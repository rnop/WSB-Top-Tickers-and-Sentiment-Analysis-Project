{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "scrape_comments_tickers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOoq3qWzc0761Id832oEXPe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rnop/WSB-Top-Tickers-and-Sentiment-Analysis-Project/blob/main/scrape_comments_tickers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if os.path.isfile(\"/content/scraper_utils.py\"):\n",
        "  print(\"'nasdaq_tickers.csv' is already downloaded.\") \n",
        "else:\n",
        "  ! wget https://raw.githubusercontent.com/rnop/WSB-Top-Tickers-and-Sentiment-Analysis-Project/main/scraper_utils.py # download CSV"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iX3Sxe51mZBO",
        "outputId": "1cf19c5a-2bdd-460e-8205-b5df4d920264"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-10 16:18:49--  https://raw.githubusercontent.com/rnop/WSB-Top-Tickers-and-Sentiment-Analysis-Project/main/scraper_utils.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3342 (3.3K) [text/plain]\n",
            "Saving to: ‚Äòscraper_utils.py‚Äô\n",
            "\n",
            "\rscraper_utils.py      0%[                    ]       0  --.-KB/s               \rscraper_utils.py    100%[===================>]   3.26K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-12-10 16:18:49 (40.2 MB/s) - ‚Äòscraper_utils.py‚Äô saved [3342/3342]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install praw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0VNeKAMo40N",
        "outputId": "23519b16-f887-42d8-f367-124828e765c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting praw\n",
            "  Downloading praw-7.5.0-py3-none-any.whl (176 kB)\n",
            "\u001b[?25l\r\u001b[K     |‚ñà‚ñâ                              | 10 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñä                            | 20 kB 10.4 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                          | 30 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                        | 40 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                      | 51 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                    | 61 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                   | 71 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                 | 81 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä               | 92 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã             | 102 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç           | 112 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé         | 122 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè       | 133 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà      | 143 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 153 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 163 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 174 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 176 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting prawcore<3,>=2.1\n",
            "  Downloading prawcore-2.3.0-py3-none-any.whl (16 kB)\n",
            "Collecting update-checker>=0.18\n",
            "  Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
            "Collecting websocket-client>=0.54.0\n",
            "  Downloading websocket_client-1.2.3-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 53 kB 2.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from prawcore<3,>=2.1->praw) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (3.0.4)\n",
            "Installing collected packages: websocket-client, update-checker, prawcore, praw\n",
            "Successfully installed praw-7.5.0 prawcore-2.3.0 update-checker-0.18.0 websocket-client-1.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scraper_utils import * \n",
        "import pandas as pd\n",
        "import praw \n",
        "import re \n",
        "import requests\n",
        "import json\n",
        "import csv\n",
        "import time\n",
        "import datetime"
      ],
      "metadata": {
        "id": "f2lAgy_qoymi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scrape Reddit Comments"
      ],
      "metadata": {
        "id": "c9pfQUijrWOh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WwpzWfZ-mFKC"
      },
      "outputs": [],
      "source": [
        "# Connect to Reddit API via praw\n",
        "reddit_creds = praw.Reddit(client_id='***', client_secret='***', user_agent='***', check_for_async=False)\n",
        "# Obtain URLs of Daily Submission Threads within time period\n",
        "urls = get_daily_discussion_urls(subreddit='wallstreetbets', before_date= str(datetime.datetime.now())[:10], after_date='2021-01-01')\n",
        "# Scrape Comments Using Each URL\n",
        "comments = get_comments(urls, reddit_creds)\n",
        "# Read Comments into DataFrame\n",
        "comments_df = comments_to_df(comments, urls)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean comments so it is easier to extract tickers\n",
        "comments_df['comment'] = comments_df.apply(lambda x: x['comment'].replace('.', ' '), axis=1)\n",
        "comments_df['comment'] = comments_df.apply(lambda x: x['comment'].replace(',', ' '), axis=1)\n",
        "comments_df['comment'] = comments_df.apply(lambda x: x['comment'].replace(\"'\", ' '), axis=1)\n",
        "\n",
        "# Some punctuations are actually useful for the sentiment model\n",
        "comments_df['comment'] = comments_df.apply(lambda x: x['comment'].replace('$', ' $ '), axis=1)\n",
        "comments_df['comment'] = comments_df.apply(lambda x: x['comment'].replace('#', ' # '), axis=1) \n",
        "comments_df['comment'] = comments_df.apply(lambda x: x['comment'].replace(\"?\", ' ? '), axis=1)\n",
        "comments_df['comment'] = comments_df.apply(lambda x: x['comment'].replace(\"!\", ' ! '), axis=1)"
      ],
      "metadata": {
        "id": "SB02DBVY5xY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(comments_df.info())\n",
        "comments_df.sample(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "id": "k3lsG02_mXVf",
        "outputId": "d3791f19-8ee7-4318-c20d-2c33fb64f5de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 224241 entries, 0 to 982\n",
            "Data columns (total 3 columns):\n",
            " #   Column   Non-Null Count   Dtype         \n",
            "---  ------   --------------   -----         \n",
            " 0   comment  224241 non-null  object        \n",
            " 1   date     224241 non-null  datetime64[ns]\n",
            " 2   title    224241 non-null  object        \n",
            "dtypes: datetime64[ns](1), object(2)\n",
            "memory usage: 6.8+ MB\n",
            "None\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>323</th>\n",
              "      <td>APHA is merging with TLRY in Q2 2021  For ever...</td>\n",
              "      <td>2021-02-09</td>\n",
              "      <td>Daily Discussion Thread for February 09, 2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>316</th>\n",
              "      <td>what happened with everyone being bulls  every...</td>\n",
              "      <td>2021-09-14</td>\n",
              "      <td>Daily Discussion Thread for September 14, 2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>853</th>\n",
              "      <td>Holy shit i bought SPY at 442 80 this morning ...</td>\n",
              "      <td>2021-08-12</td>\n",
              "      <td>Daily Discussion Thread for August 12, 2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>295</th>\n",
              "      <td>[removed]</td>\n",
              "      <td>2021-09-02</td>\n",
              "      <td>Daily Discussion Thread for September 02, 2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>417</th>\n",
              "      <td>Only lost 3k this week üòé</td>\n",
              "      <td>2021-11-12</td>\n",
              "      <td>Daily Discussion Thread for November 12, 2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>[deleted]</td>\n",
              "      <td>2021-09-02</td>\n",
              "      <td>Daily Discussion Thread for September 02, 2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>388</th>\n",
              "      <td>Don‚Äôt be scared DIS the green isn‚Äôt gonna hurt...</td>\n",
              "      <td>2021-11-29</td>\n",
              "      <td>Daily Discussion Thread for November 29, 2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305</th>\n",
              "      <td>Y‚Äôall really bought TSLA calls</td>\n",
              "      <td>2021-07-26</td>\n",
              "      <td>Daily Discussion Thread for July 26, 2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206</th>\n",
              "      <td>Honestly  I don‚Äôt understand why I buy anythin...</td>\n",
              "      <td>2021-09-23</td>\n",
              "      <td>Daily Discussion Thread for September 23, 2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>See that big red SPY dildo ?  That‚Äôs exactly w...</td>\n",
              "      <td>2021-10-27</td>\n",
              "      <td>Daily Discussion Thread for October 27, 2021</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               comment  ...                                           title\n",
              "323  APHA is merging with TLRY in Q2 2021  For ever...  ...   Daily Discussion Thread for February 09, 2021\n",
              "316  what happened with everyone being bulls  every...  ...  Daily Discussion Thread for September 14, 2021\n",
              "853  Holy shit i bought SPY at 442 80 this morning ...  ...     Daily Discussion Thread for August 12, 2021\n",
              "295                                          [removed]  ...  Daily Discussion Thread for September 02, 2021\n",
              "417                           Only lost 3k this week üòé  ...   Daily Discussion Thread for November 12, 2021\n",
              "55                                           [deleted]  ...  Daily Discussion Thread for September 02, 2021\n",
              "388  Don‚Äôt be scared DIS the green isn‚Äôt gonna hurt...  ...   Daily Discussion Thread for November 29, 2021\n",
              "305                     Y‚Äôall really bought TSLA calls  ...       Daily Discussion Thread for July 26, 2021\n",
              "206  Honestly  I don‚Äôt understand why I buy anythin...  ...  Daily Discussion Thread for September 23, 2021\n",
              "122  See that big red SPY dildo ?  That‚Äôs exactly w...  ...    Daily Discussion Thread for October 27, 2021\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "comments_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "NkeG6PhE4_oB",
        "outputId": "abb42255-ccef-415c-c265-72b28413dbf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What am I even supposed to do with myself for ...</td>\n",
              "      <td>2021-01-01</td>\n",
              "      <td>Daily Discussion Thread for January 01, 2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Goddamn if there‚Äôs one sub I can go on to find...</td>\n",
              "      <td>2021-01-01</td>\n",
              "      <td>Daily Discussion Thread for January 01, 2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I usually ignore most of the shit people say o...</td>\n",
              "      <td>2021-01-01</td>\n",
              "      <td>Daily Discussion Thread for January 01, 2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>‚ÄúSorry honey can‚Äôt stay up for midnight  marke...</td>\n",
              "      <td>2021-01-01</td>\n",
              "      <td>Daily Discussion Thread for January 01, 2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What if 2020 is so inescapable that today is a...</td>\n",
              "      <td>2021-01-01</td>\n",
              "      <td>Daily Discussion Thread for January 01, 2021</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             comment  ...                                         title\n",
              "0  What am I even supposed to do with myself for ...  ...  Daily Discussion Thread for January 01, 2021\n",
              "1  Goddamn if there‚Äôs one sub I can go on to find...  ...  Daily Discussion Thread for January 01, 2021\n",
              "2  I usually ignore most of the shit people say o...  ...  Daily Discussion Thread for January 01, 2021\n",
              "3  ‚ÄúSorry honey can‚Äôt stay up for midnight  marke...  ...  Daily Discussion Thread for January 01, 2021\n",
              "4  What if 2020 is so inescapable that today is a...  ...  Daily Discussion Thread for January 01, 2021\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Stock Tickers"
      ],
      "metadata": {
        "id": "bQsupgmzrY5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if os.path.isfile(\"/content/nasdaq_tickers.csv\"):\n",
        "  print(\"'nasdaq_tickers.csv' is already downloaded.\") \n",
        "else:\n",
        "  ! wget https://raw.githubusercontent.com/rnop/WSB-Top-Tickers-and-Sentiment-Analysis-Project/main/nasdaq_tickers.csv # download CSV"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9u1ZoMXXKBU",
        "outputId": "77e9ef17-a17a-4ce1-9a8c-085921f28895"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-10 17:27:37--  https://raw.githubusercontent.com/rnop/WSB-Top-Tickers-and-Sentiment-Analysis-Project/main/nasdaq_tickers.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 618348 (604K) [text/plain]\n",
            "Saving to: ‚Äònasdaq_tickers.csv‚Äô\n",
            "\n",
            "nasdaq_tickers.csv  100%[===================>] 603.86K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2021-12-10 17:27:38 (14.1 MB/s) - ‚Äònasdaq_tickers.csv‚Äô saved [618348/618348]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tickers = pd.read_csv('nasdaq_tickers.csv')\n",
        "\n",
        "# Clean Last Sale column for filtering\n",
        "tickers['Last Sale'] = pd.to_numeric(tickers['Last Sale'].str.replace('$', ''))\n",
        "\n",
        "# Filter tickers based on price of shares, market cap, and country\n",
        "tickers = tickers[(tickers['Last Sale'] > 5.00) & \n",
        "                  (tickers['Market Cap'] > 100000000) &\n",
        "                  (tickers['Country'].isin(['United States', 'Canada']))]\n",
        "\n",
        "tickers = tickers[['Symbol', 'Name', 'Sector']]\n",
        "tickers = tickers.append({'Symbol': 'SPY', 'Name':'S&P500', 'Sector':'ETF'}, ignore_index=True)\n",
        "\n",
        "# Add tickers, company name, and sector\n",
        "tickers = tickers.append({'Symbol': 'PLTR', 'Name':'Palantir', 'Sector':'Technology'}, ignore_index=True)\n",
        "tickers = tickers.append({'Symbol': 'GME', 'Name':'Gamestop', 'Sector':'Meme'}, ignore_index=True)\n",
        "tickers = tickers.append({'Symbol': 'AMC', 'Name':'AMC', 'Sector':'Meme'}, ignore_index=True)\n",
        "tickers = tickers.append({'Symbol': 'BB', 'Name':'BlackBerry', 'Sector':'Meme'}, ignore_index=True)\n",
        "tickers = tickers.append({'Symbol': 'CLOV', 'Name':'Clover Health', 'Sector':'Meme'}, ignore_index=True)\n",
        "tickers = tickers.append({'Symbol': 'CHWY', 'Name':'Chewy', 'Sector':'Meme'}, ignore_index=True)\n",
        "tickers = tickers.append({'Symbol': 'SPCE', 'Name':'Virgin Galactic', 'Sector':'Meme'}, ignore_index=True)\n",
        "tickers = tickers.append({'Symbol': 'NOK', 'Name':'Nokia', 'Sector':'Meme'}, ignore_index=True)\n",
        "tickers = tickers.append({'Symbol': 'NAKD', 'Name':'Naked Brands', 'Sector':'Meme'}, ignore_index=True)\n",
        "tickers = tickers.append({'Symbol': 'CCL', 'Name':'Carnival Cruise Line', 'Sector':'Meme'}, ignore_index=True)\n",
        "tickers = tickers.append({'Symbol': 'NCLH', 'Name':'Norwegian Cruise Line', 'Sector':'Meme'}, ignore_index=True)\n",
        "tickers = tickers.append({'Symbol': 'RKT', 'Name':'Rocket Insurance', 'Sector':'Meme'}, ignore_index=True)\n",
        "tickers = tickers.append({'Symbol': 'X', 'Name':'US Steel Corporation', 'Sector':'Energy'}, ignore_index=True)\n",
        "tickers = tickers.append({'Symbol': 'WISH', 'Name':'WISH', 'Sector':'Meme'}, ignore_index=True)\n",
        "tickers = tickers.append({'Symbol': 'JPM', 'Name':'JP Morgan', 'Sector':'Finance'}, ignore_index=True)\n",
        "tickers = tickers.append({'Symbol': 'BAC', 'Name':'Bank of America', 'Sector':'Finance'}, ignore_index=True)\n",
        "tickers = tickers.append({'Symbol': 'V', 'Name':'Visa', 'Sector':'Finance'}, ignore_index=True)\n",
        "tickers = tickers.append({'Symbol': 'PFE', 'Name':'Pfizer', 'Sector':'Health Care'}, ignore_index=True)\n",
        "\n",
        "\n",
        "tickers = tickers.append({'Symbol': 'DIS', 'Name':'Disney', 'Sector':'Consumer Services'}, ignore_index=True)\n",
        "tickers = tickers.append({'Symbol': 'BABA', 'Name':'Alibaba', 'Sector':'Consumer Durables'}, ignore_index=True)\n",
        "tickers = tickers.append({'Symbol': 'JD', 'Name':'JD', 'Sector':'Consumer Durables'}, ignore_index=True)\n",
        "tickers = tickers.append({'Symbol': 'NIO', 'Name':'NIO', 'Sector':'Technology'}, ignore_index=True)\n",
        "\n",
        "# Remove commonly mistakened tickers made by users\n",
        "mistakened_tickers = ['ON', 'ME', 'GO','HAS','GOOD','OPEN','LOVE','LMAO','EVER','PLAY','REAL','LIFE','RUN','VERY',\n",
        "                      'CASH','HOPE','CAR','FREE','GAIN','GLAD','COOL','KIDS','CARE','HEAR', 'APP', 'STEP', 'TECH',\n",
        "                      'PLUS','FUND','FAT','RENT', 'POW', 'TIL','JACK','MON','ROLL']\n",
        "\n",
        "tickers = tickers[~tickers['Symbol'].isin(mistakened_tickers)]\n",
        "\n",
        "tickers.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "A2iFCAHdrYuj",
        "outputId": "f7436c27-515a-4044-d630-e73fcddfa94b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Symbol</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sector</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>361</th>\n",
              "      <td>CCD</td>\n",
              "      <td>Calamos Dynamic Convertible &amp; Income Fund Comm...</td>\n",
              "      <td>Finance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1732</th>\n",
              "      <td>ROAD</td>\n",
              "      <td>Construction Partners Inc. Class A Common Stock</td>\n",
              "      <td>Capital Goods</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1933</th>\n",
              "      <td>STRO</td>\n",
              "      <td>Sutro Biopharma Inc. Common Stock</td>\n",
              "      <td>Health Care</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1750</th>\n",
              "      <td>RRR</td>\n",
              "      <td>Red Rock Resorts Inc. Class A Common Stock</td>\n",
              "      <td>Consumer Services</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1269</th>\n",
              "      <td>MCMJ</td>\n",
              "      <td>Merida Merger Corp. I Common Stock</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Symbol  ...             Sector\n",
              "361     CCD  ...            Finance\n",
              "1732   ROAD  ...      Capital Goods\n",
              "1933   STRO  ...        Health Care\n",
              "1750    RRR  ...  Consumer Services\n",
              "1269   MCMJ  ...                NaN\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Search for Tickers in Comments"
      ],
      "metadata": {
        "id": "Ow9yxaq_0gPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ticker_in_comment = []\n",
        "for comment in comments_df['comment']:\n",
        "  all_tickers_in_comment = []\n",
        "  for word in comment.split():\n",
        "    if word.upper() in tickers['Symbol'].values:\n",
        "      all_tickers_in_comment.append(word.upper())\n",
        "  # ticker_in_comment.append(all_tickers_in_comment)\n",
        "  ticker_in_comment.append(list(set(all_tickers_in_comment))) # some users write the ticker multiple times in their post\n",
        "\n",
        "comments_df['ticker_in_comment'] = ticker_in_comment"
      ],
      "metadata": {
        "id": "oEJZwCVs0f_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comments_df.to_csv('submission_comments_tickers.csv', index=False)"
      ],
      "metadata": {
        "id": "ASiWhR-TqoKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7gvNuVOXI0A4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}